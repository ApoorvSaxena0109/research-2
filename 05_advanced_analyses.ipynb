{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Analyses: Leveraging Colab Pro Compute\n",
    "\n",
    "This notebook implements computationally intensive analyses that benefit from Colab Pro's TPU/GPU resources.\n",
    "\n",
    "## Contents\n",
    "1. **Stacked DiD** - Addresses TWFE bias (Callaway-Sant'Anna, Sun-Abraham)\n",
    "2. **Synthetic Control Method** - Alternative identification\n",
    "3. **Placebo Tests in Time** - Validate no pre-trend effects\n",
    "4. **Bootstrap Inference** - Robust confidence intervals\n",
    "5. **Matched DiD** - Propensity score matching + DiD\n",
    "6. **Additional Outcome Variables** - What else is \"hollowing\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install linearmodels pyfixest scikit-learn joblib tqdm -q\n",
    "print(\"Packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.panel import PanelOLS\n",
    "from scipy import stats\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "N_CORES = multiprocessing.cpu_count()\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_PATH = Path('/content/drive/MyDrive/Paper_2')\n",
    "\n",
    "print(f\"CPU cores: {N_CORES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis panel from previous notebook\n",
    "try:\n",
    "    panel = pd.read_parquet(DATA_PATH / 'analysis_panel_hollow_firm.parquet')\n",
    "    print(f\"Loaded panel: {panel.shape}\")\n",
    "except:\n",
    "    print(\"Run notebook 04 first to create analysis panel\")\n",
    "    raise\n",
    "\n",
    "# Identify firm ID column\n",
    "FIRM_ID = 'firm_id' if 'firm_id' in panel.columns else panel.columns[0]\n",
    "print(f\"Firm ID: {FIRM_ID}\")\n",
    "print(f\"Firms: {panel[FIRM_ID].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Placebo Tests in Time\n",
    "\n",
    "**Purpose:** Test whether we find \"effects\" at fake treatment dates (before ChatGPT).\n",
    "\n",
    "If the true effect is causal, we should find no significant effects at placebo dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_placebo_time_test(df, outcome, firm_id, time_var='period',\n",
    "                          true_event_yq=2022*4+4):\n",
    "    \"\"\"\n",
    "    Run DiD at multiple placebo event dates.\n",
    "    Only use pre-treatment data to avoid contamination.\n",
    "    \"\"\"\n",
    "    # Use only pre-treatment data\n",
    "    pre_data = df[df['yearquarter'] < true_event_yq].copy()\n",
    "    \n",
    "    # Get available quarters for placebo tests\n",
    "    quarters = sorted(pre_data['yearquarter'].unique())\n",
    "    \n",
    "    # Test placebo dates (leaving 4 quarters pre and post for each test)\n",
    "    placebo_quarters = quarters[4:-4]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for placebo_yq in tqdm(placebo_quarters, desc=\"Placebo time tests\"):\n",
    "        # Create placebo post indicator\n",
    "        test_data = pre_data.copy()\n",
    "        test_data['post_placebo'] = (test_data['yearquarter'] >= placebo_yq).astype(int)\n",
    "        test_data['treat_x_post_placebo'] = test_data['treated'] * test_data['post_placebo']\n",
    "        \n",
    "        try:\n",
    "            reg_data = test_data[[firm_id, time_var, outcome, 'treat_x_post_placebo']].dropna()\n",
    "            reg_data = reg_data.set_index([firm_id, time_var])\n",
    "            \n",
    "            y = reg_data[outcome]\n",
    "            X = sm.add_constant(reg_data[['treat_x_post_placebo']])\n",
    "            \n",
    "            model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "            result = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "            \n",
    "            year = (placebo_yq - 1) // 4\n",
    "            quarter = ((placebo_yq - 1) % 4) + 1\n",
    "            \n",
    "            results.append({\n",
    "                'placebo_date': f\"{year}Q{quarter}\",\n",
    "                'yearquarter': placebo_yq,\n",
    "                'coef': result.params['treat_x_post_placebo'],\n",
    "                'se': result.std_errors['treat_x_post_placebo'],\n",
    "                'pval': result.pvalues['treat_x_post_placebo'],\n",
    "                'nobs': result.nobs\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run placebo time tests\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PLACEBO TESTS IN TIME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "placebo_time_results = run_placebo_time_test(\n",
    "    panel, 'sga_efficiency', FIRM_ID, 'period'\n",
    ")\n",
    "\n",
    "print(f\"\\nPlacebo tests completed: {len(placebo_time_results)}\")\n",
    "print(f\"Significant at 5%: {(placebo_time_results['pval'] < 0.05).sum()}\")\n",
    "print(f\"Expected by chance: {len(placebo_time_results) * 0.05:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot placebo time test results\n",
    "def plot_placebo_time_tests(placebo_results, true_date='2022Q4'):\n",
    "    \"\"\"\n",
    "    Plot coefficients from placebo time tests.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Plot coefficients with CIs\n",
    "    x = range(len(placebo_results))\n",
    "    \n",
    "    ax.errorbar(x, placebo_results['coef'], \n",
    "                yerr=1.96 * placebo_results['se'],\n",
    "                fmt='o', color='#3498DB', capsize=3, capthick=1,\n",
    "                label='Placebo Coefficients')\n",
    "    \n",
    "    # Reference line at 0\n",
    "    ax.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Mark significant results\n",
    "    sig_mask = placebo_results['pval'] < 0.05\n",
    "    if sig_mask.any():\n",
    "        ax.scatter(np.array(x)[sig_mask], placebo_results.loc[sig_mask, 'coef'],\n",
    "                   color='#E74C3C', s=100, marker='*', zorder=5,\n",
    "                   label='Significant at 5%')\n",
    "    \n",
    "    ax.set_xticks(x[::4])  # Show every 4th label\n",
    "    ax.set_xticklabels(placebo_results['placebo_date'].iloc[::4], rotation=45)\n",
    "    \n",
    "    ax.set_xlabel('Placebo Event Date', fontsize=12)\n",
    "    ax.set_ylabel('DiD Coefficient', fontsize=12)\n",
    "    ax.set_title('Figure 4: Placebo Tests in Time\\n(Pre-ChatGPT Period Only)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "if len(placebo_time_results) > 0:\n",
    "    fig = plot_placebo_time_tests(placebo_time_results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Bootstrap Confidence Intervals\n",
    "\n",
    "More robust inference through bootstrap (cluster bootstrap at firm level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_did_single(df, outcome, firm_id, time_var, seed):\n",
    "    \"\"\"\n",
    "    Single bootstrap iteration with cluster resampling.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    try:\n",
    "        # Cluster bootstrap: resample firms with replacement\n",
    "        firms = df[firm_id].unique()\n",
    "        boot_firms = np.random.choice(firms, size=len(firms), replace=True)\n",
    "        \n",
    "        # Create bootstrap sample\n",
    "        boot_dfs = []\n",
    "        for i, firm in enumerate(boot_firms):\n",
    "            firm_data = df[df[firm_id] == firm].copy()\n",
    "            firm_data['boot_firm_id'] = i  # New ID to handle duplicates\n",
    "            boot_dfs.append(firm_data)\n",
    "        \n",
    "        boot_df = pd.concat(boot_dfs, ignore_index=True)\n",
    "        \n",
    "        # Run regression\n",
    "        reg_data = boot_df[['boot_firm_id', time_var, outcome, 'treated_x_post']].dropna()\n",
    "        reg_data = reg_data.set_index(['boot_firm_id', time_var])\n",
    "        \n",
    "        y = reg_data[outcome]\n",
    "        X = sm.add_constant(reg_data[['treated_x_post']])\n",
    "        \n",
    "        model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "        result = model.fit()\n",
    "        \n",
    "        return result.params['treated_x_post']\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def bootstrap_confidence_intervals(df, outcome, firm_id, time_var='period',\n",
    "                                   n_bootstrap=2000, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence intervals.\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning {n_bootstrap:,} bootstrap iterations...\")\n",
    "    \n",
    "    seeds = np.random.randint(0, 1e7, n_bootstrap)\n",
    "    \n",
    "    boot_coefs = Parallel(n_jobs=n_jobs, verbose=5)(\n",
    "        delayed(bootstrap_did_single)(df, outcome, firm_id, time_var, seed)\n",
    "        for seed in seeds\n",
    "    )\n",
    "    \n",
    "    boot_coefs = np.array([c for c in boot_coefs if not np.isnan(c)])\n",
    "    \n",
    "    # Compute confidence intervals\n",
    "    ci_percentile = np.percentile(boot_coefs, [2.5, 97.5])\n",
    "    \n",
    "    # Bias-corrected accelerated (BCa) would be better but more complex\n",
    "    \n",
    "    return boot_coefs, ci_percentile\n",
    "\n",
    "# Run bootstrap\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BOOTSTRAP CONFIDENCE INTERVALS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "boot_coefs, boot_ci = bootstrap_confidence_intervals(\n",
    "    panel, 'sga_efficiency', FIRM_ID, 'period',\n",
    "    n_bootstrap=2000, n_jobs=N_CORES\n",
    ")\n",
    "\n",
    "print(f\"\\nBootstrap Results:\")\n",
    "print(f\"  Mean: {boot_coefs.mean():.6f}\")\n",
    "print(f\"  Std Dev: {boot_coefs.std():.6f}\")\n",
    "print(f\"  95% CI: [{boot_ci[0]:.6f}, {boot_ci[1]:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Propensity Score Matching + DiD\n",
    "\n",
    "Match treated and control firms on pre-treatment characteristics, then run DiD on matched sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propensity_score_matching(df, firm_id, treatment_col='treated',\n",
    "                               covariates=None, n_neighbors=1):\n",
    "    \"\"\"\n",
    "    Propensity score matching at firm level using pre-treatment characteristics.\n",
    "    \"\"\"\n",
    "    # Get pre-period firm-level characteristics\n",
    "    pre_data = df[df['post'] == 0]\n",
    "    \n",
    "    # Find available covariates\n",
    "    if covariates is None:\n",
    "        potential = ['log_revenue', 'log_employees', 'log_assets', 'sga_efficiency']\n",
    "        covariates = [c for c in potential if c in pre_data.columns]\n",
    "    \n",
    "    print(f\"Matching on: {covariates}\")\n",
    "    \n",
    "    # Compute firm-level averages\n",
    "    firm_chars = pre_data.groupby(firm_id).agg({\n",
    "        treatment_col: 'first',\n",
    "        **{c: 'mean' for c in covariates}\n",
    "    }).reset_index()\n",
    "    \n",
    "    firm_chars = firm_chars.dropna()\n",
    "    \n",
    "    print(f\"Firms for matching: {len(firm_chars)}\")\n",
    "    print(f\"  Treated: {(firm_chars[treatment_col]==1).sum()}\")\n",
    "    print(f\"  Control: {(firm_chars[treatment_col]==0).sum()}\")\n",
    "    \n",
    "    # Estimate propensity scores\n",
    "    X = firm_chars[covariates]\n",
    "    y = firm_chars[treatment_col]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Logistic regression for propensity scores\n",
    "    ps_model = LogisticRegression(random_state=RANDOM_SEED, max_iter=1000)\n",
    "    ps_model.fit(X_scaled, y)\n",
    "    \n",
    "    firm_chars['propensity_score'] = ps_model.predict_proba(X_scaled)[:, 1]\n",
    "    \n",
    "    # Nearest neighbor matching\n",
    "    treated = firm_chars[firm_chars[treatment_col] == 1]\n",
    "    control = firm_chars[firm_chars[treatment_col] == 0]\n",
    "    \n",
    "    # Fit NN on control propensity scores\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
    "    nn.fit(control[['propensity_score']])\n",
    "    \n",
    "    # Find matches for treated\n",
    "    distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
    "    \n",
    "    # Get matched control firm IDs\n",
    "    matched_control_ids = control.iloc[indices.flatten()][firm_id].values\n",
    "    treated_ids = treated[firm_id].values\n",
    "    \n",
    "    # Combine matched sample\n",
    "    matched_firms = np.concatenate([treated_ids, matched_control_ids])\n",
    "    \n",
    "    print(f\"\\nMatched sample: {len(matched_firms)} firms\")\n",
    "    \n",
    "    return matched_firms, firm_chars\n",
    "\n",
    "# Run matching\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROPENSITY SCORE MATCHING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "matched_firms, firm_chars = propensity_score_matching(panel, FIRM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DiD on matched sample\n",
    "matched_panel = panel[panel[FIRM_ID].isin(matched_firms)].copy()\n",
    "\n",
    "print(f\"\\nMatched sample:\")\n",
    "print(f\"  Observations: {len(matched_panel):,}\")\n",
    "print(f\"  Firms: {matched_panel[FIRM_ID].nunique():,}\")\n",
    "\n",
    "# Run DiD\n",
    "reg_data = matched_panel[[FIRM_ID, 'period', 'sga_efficiency', 'treated_x_post']].dropna()\n",
    "reg_data = reg_data.set_index([FIRM_ID, 'period'])\n",
    "\n",
    "y = reg_data['sga_efficiency']\n",
    "X = sm.add_constant(reg_data[['treated_x_post']])\n",
    "\n",
    "model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "matched_result = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "print(\"\\nMatched DiD Results:\")\n",
    "print(matched_result.summary.tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check covariate balance after matching\n",
    "def check_balance(df, firm_chars, matched_firms, firm_id, covariates):\n",
    "    \"\"\"\n",
    "    Check covariate balance before and after matching.\n",
    "    \"\"\"\n",
    "    # Before matching\n",
    "    before = firm_chars.copy()\n",
    "    \n",
    "    # After matching\n",
    "    after = firm_chars[firm_chars[firm_id].isin(matched_firms)].copy()\n",
    "    \n",
    "    balance_results = []\n",
    "    \n",
    "    for cov in covariates:\n",
    "        if cov not in firm_chars.columns:\n",
    "            continue\n",
    "            \n",
    "        # Before\n",
    "        t_before = before[before['treated']==1][cov]\n",
    "        c_before = before[before['treated']==0][cov]\n",
    "        std_diff_before = (t_before.mean() - c_before.mean()) / np.sqrt((t_before.var() + c_before.var())/2)\n",
    "        \n",
    "        # After\n",
    "        t_after = after[after['treated']==1][cov]\n",
    "        c_after = after[after['treated']==0][cov]\n",
    "        std_diff_after = (t_after.mean() - c_after.mean()) / np.sqrt((t_after.var() + c_after.var())/2)\n",
    "        \n",
    "        balance_results.append({\n",
    "            'Covariate': cov,\n",
    "            'Std Diff (Before)': std_diff_before,\n",
    "            'Std Diff (After)': std_diff_after,\n",
    "            'Improvement': abs(std_diff_before) - abs(std_diff_after)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(balance_results)\n",
    "\n",
    "covariates = ['log_revenue', 'log_employees', 'sga_efficiency']\n",
    "covariates = [c for c in covariates if c in firm_chars.columns]\n",
    "\n",
    "balance = check_balance(panel, firm_chars, matched_firms, FIRM_ID, covariates)\n",
    "print(\"\\nCovariate Balance:\")\n",
    "display(balance.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Industry Leave-One-Out Robustness\n",
    "\n",
    "Check that results aren't driven by a single industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_industry(df, outcome, firm_id, time_var='period',\n",
    "                           industry_col=None):\n",
    "    \"\"\"\n",
    "    Re-run DiD excluding each industry one at a time.\n",
    "    \"\"\"\n",
    "    if industry_col is None or industry_col not in df.columns:\n",
    "        # Try to find industry column\n",
    "        for col in df.columns:\n",
    "            if 'industry' in col.lower() or 'sector' in col.lower():\n",
    "                industry_col = col\n",
    "                break\n",
    "    \n",
    "    if industry_col is None:\n",
    "        print(\"No industry column found\")\n",
    "        return None\n",
    "    \n",
    "    industries = df[industry_col].dropna().unique()\n",
    "    print(f\"Testing {len(industries)} industries\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for industry in tqdm(industries, desc=\"Leave-one-out\"):\n",
    "        subset = df[df[industry_col] != industry]\n",
    "        \n",
    "        try:\n",
    "            reg_data = subset[[firm_id, time_var, outcome, 'treated_x_post']].dropna()\n",
    "            reg_data = reg_data.set_index([firm_id, time_var])\n",
    "            \n",
    "            y = reg_data[outcome]\n",
    "            X = sm.add_constant(reg_data[['treated_x_post']])\n",
    "            \n",
    "            model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "            result = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "            \n",
    "            results.append({\n",
    "                'excluded_industry': str(industry)[:50],\n",
    "                'coef': result.params['treated_x_post'],\n",
    "                'se': result.std_errors['treated_x_post'],\n",
    "                'pval': result.pvalues['treated_x_post'],\n",
    "                'nobs': result.nobs\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run leave-one-out\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LEAVE-ONE-OUT INDUSTRY ROBUSTNESS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "loo_results = leave_one_out_industry(panel, 'sga_efficiency', FIRM_ID, 'period')\n",
    "\n",
    "if loo_results is not None and len(loo_results) > 0:\n",
    "    print(f\"\\nCoefficient range: [{loo_results['coef'].min():.6f}, {loo_results['coef'].max():.6f}]\")\n",
    "    print(f\"All coefficients significant: {(loo_results['pval'] < 0.05).all()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot leave-one-out results\n",
    "if loo_results is not None and len(loo_results) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    loo_sorted = loo_results.sort_values('coef')\n",
    "    \n",
    "    y_pos = range(len(loo_sorted))\n",
    "    \n",
    "    ax.barh(y_pos, loo_sorted['coef'], xerr=1.96*loo_sorted['se'],\n",
    "            color='#3498DB', alpha=0.7, capsize=2)\n",
    "    \n",
    "    ax.axvline(0, color='black', linewidth=0.5)\n",
    "    \n",
    "    # Show baseline\n",
    "    baseline = panel[[FIRM_ID, 'period', 'sga_efficiency', 'treated_x_post']].dropna()\n",
    "    baseline = baseline.set_index([FIRM_ID, 'period'])\n",
    "    baseline_model = PanelOLS(baseline['sga_efficiency'], \n",
    "                               sm.add_constant(baseline[['treated_x_post']]),\n",
    "                               entity_effects=True, time_effects=True)\n",
    "    baseline_coef = baseline_model.fit().params['treated_x_post']\n",
    "    ax.axvline(baseline_coef, color='#E74C3C', linewidth=2, linestyle='--',\n",
    "               label=f'Full sample: {baseline_coef:.4f}')\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(loo_sorted['excluded_industry'], fontsize=8)\n",
    "    \n",
    "    ax.set_xlabel('DiD Coefficient', fontsize=12)\n",
    "    ax.set_title('Figure 5: Leave-One-Out Industry Robustness', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Alternative Outcome Variables\n",
    "\n",
    "What else might be \"hollowing\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional outcome variables\n",
    "def create_additional_outcomes(df, var_map):\n",
    "    \"\"\"\n",
    "    Create additional outcome variables for robustness.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Find available columns\n",
    "    revenue_col = None\n",
    "    employee_col = None\n",
    "    ebitda_col = None\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if ('revenue' in col_lower or 'sales' in col_lower) and revenue_col is None:\n",
    "            revenue_col = col\n",
    "        elif 'employee' in col_lower and employee_col is None:\n",
    "            employee_col = col\n",
    "        elif 'ebitda' in col_lower and ebitda_col is None:\n",
    "            ebitda_col = col\n",
    "    \n",
    "    # Revenue growth (if we have lagged values)\n",
    "    if revenue_col:\n",
    "        df['revenue_growth'] = df.groupby(FIRM_ID)[revenue_col].pct_change(4)  # YoY\n",
    "        df['revenue_growth'] = winsorize(df['revenue_growth'], 0.01, 0.99)\n",
    "    \n",
    "    # Employee intensity (employees / revenue)\n",
    "    if employee_col and revenue_col:\n",
    "        mask = (df[revenue_col] > 0)\n",
    "        df['employee_intensity'] = np.nan\n",
    "        df.loc[mask, 'employee_intensity'] = df.loc[mask, employee_col] / df.loc[mask, revenue_col] * 1e6\n",
    "        df['employee_intensity'] = winsorize(df['employee_intensity'], 0.01, 0.99)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def winsorize(series, lower=0.01, upper=0.99):\n",
    "    lower_bound = series.quantile(lower)\n",
    "    upper_bound = series.quantile(upper)\n",
    "    return series.clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Create additional outcomes\n",
    "panel = create_additional_outcomes(panel, None)\n",
    "print(\"Additional outcomes created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DiD for all outcomes\n",
    "outcomes = [\n",
    "    ('sga_efficiency', 'SG&A Efficiency (SG&A/Revenue)'),\n",
    "    ('revenue_per_employee', 'Revenue per Employee'),\n",
    "    ('ebitda_margin', 'EBITDA Margin'),\n",
    "    ('employee_intensity', 'Employee Intensity (Emp/Rev)'),\n",
    "    ('revenue_growth', 'Revenue Growth (YoY)')\n",
    "]\n",
    "\n",
    "outcomes = [(var, label) for var, label in outcomes if var in panel.columns]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLE 5: MULTIPLE OUTCOME ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "multi_outcome_results = []\n",
    "\n",
    "for var, label in outcomes:\n",
    "    try:\n",
    "        reg_data = panel[[FIRM_ID, 'period', var, 'treated_x_post']].dropna()\n",
    "        if len(reg_data) < 100:\n",
    "            continue\n",
    "            \n",
    "        reg_data = reg_data.set_index([FIRM_ID, 'period'])\n",
    "        \n",
    "        y = reg_data[var]\n",
    "        X = sm.add_constant(reg_data[['treated_x_post']])\n",
    "        \n",
    "        model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "        result = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "        \n",
    "        multi_outcome_results.append({\n",
    "            'Outcome': label,\n",
    "            'β': result.params['treated_x_post'],\n",
    "            'SE': result.std_errors['treated_x_post'],\n",
    "            't-stat': result.tstats['treated_x_post'],\n",
    "            'p-value': result.pvalues['treated_x_post'],\n",
    "            'N': result.nobs,\n",
    "            'R² (within)': result.rsquared_within\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {label}: {e}\")\n",
    "\n",
    "if multi_outcome_results:\n",
    "    results_df = pd.DataFrame(multi_outcome_results)\n",
    "    display(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary of All Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROBUSTNESS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                      ROBUSTNESS CHECK SUMMARY                               │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\"\"\")\n",
    "\n",
    "# Main result\n",
    "main_data = panel[[FIRM_ID, 'period', 'sga_efficiency', 'treated_x_post']].dropna()\n",
    "main_data = main_data.set_index([FIRM_ID, 'period'])\n",
    "main_model = PanelOLS(main_data['sga_efficiency'], \n",
    "                       sm.add_constant(main_data[['treated_x_post']]),\n",
    "                       entity_effects=True, time_effects=True)\n",
    "main_result = main_model.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "print(f\"│  1. Main DiD Result                β = {main_result.params['treated_x_post']:>10.6f}  p = {main_result.pvalues['treated_x_post']:.4f}  │\")\n",
    "\n",
    "# Bootstrap CI\n",
    "if 'boot_ci' in dir():\n",
    "    print(f\"│  2. Bootstrap 95% CI               [{boot_ci[0]:>10.6f}, {boot_ci[1]:.6f}]          │\")\n",
    "\n",
    "# Matched sample\n",
    "if 'matched_result' in dir():\n",
    "    print(f\"│  3. Matched Sample DiD             β = {matched_result.params['treated_x_post']:>10.6f}  p = {matched_result.pvalues['treated_x_post']:.4f}  │\")\n",
    "\n",
    "# Placebo tests\n",
    "if 'placebo_time_results' in dir() and len(placebo_time_results) > 0:\n",
    "    sig_rate = (placebo_time_results['pval'] < 0.05).mean() * 100\n",
    "    print(f\"│  4. Placebo Time Tests             {sig_rate:>5.1f}% significant (expect 5%)           │\")\n",
    "\n",
    "# Leave-one-out\n",
    "if 'loo_results' in dir() and loo_results is not None:\n",
    "    all_sig = (loo_results['pval'] < 0.05).all()\n",
    "    status = \"✓ All significant\" if all_sig else \"✗ Some not significant\"\n",
    "    print(f\"│  5. Leave-One-Out Industry         {status:>30}  │\")\n",
    "\n",
    "print(\"└─────────────────────────────────────────────────────────────────────────────┘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "panel.to_parquet(DATA_PATH / 'analysis_panel_full.parquet', index=False)\n",
    "\n",
    "if 'boot_coefs' in dir():\n",
    "    np.save(DATA_PATH / 'bootstrap_coefficients.npy', boot_coefs)\n",
    "\n",
    "if 'placebo_time_results' in dir() and placebo_time_results is not None:\n",
    "    placebo_time_results.to_csv(DATA_PATH / 'placebo_time_results.csv', index=False)\n",
    "\n",
    "if 'loo_results' in dir() and loo_results is not None:\n",
    "    loo_results.to_csv(DATA_PATH / 'leave_one_out_results.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ All results saved to Google Drive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
