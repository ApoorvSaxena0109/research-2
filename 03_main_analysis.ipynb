{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis: GenAI Impact on Corporate Policy\n",
    "\n",
    "## Difference-in-Differences & Event Study Analysis\n",
    "\n",
    "This notebook implements the main empirical analysis:\n",
    "1. Panel construction (wide to long format)\n",
    "2. Difference-in-Differences estimation\n",
    "3. Event study with dynamic treatment effects\n",
    "4. Robustness checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for panel econometrics\n",
    "!pip install linearmodels pyfixest -q\n",
    "print(\"Packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Econometrics\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.panel import PanelOLS, PooledOLS\n",
    "from linearmodels import PanelOLS as PanelFE\n",
    "import pyfixest as pf\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "DATA_PATH = Path('/content/drive/MyDrive/Paper_2')\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data with AI Exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load processed data, fall back to raw\n",
    "try:\n",
    "    df = pd.read_parquet(DATA_PATH / 'data_with_ai_exposure.parquet')\n",
    "    print(f\"Loaded processed data: {df.shape}\")\n",
    "except:\n",
    "    print(\"Run notebook 02 first, or loading raw data...\")\n",
    "    df1 = pd.read_excel(DATA_PATH / 'Data_1.xlsx')\n",
    "    df2 = pd.read_excel(DATA_PATH / 'Data_2.xlsx')\n",
    "    \n",
    "    common_cols = set(df1.columns) & set(df2.columns)\n",
    "    if common_cols:\n",
    "        df = pd.merge(df1, df2, on=list(common_cols), how='outer')\n",
    "    elif len(df1) == len(df2):\n",
    "        df = pd.concat([df1, df2], axis=1)\n",
    "    else:\n",
    "        df = df1\n",
    "    print(f\"Loaded raw data: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Wide to Long Panel Format\n",
    "\n",
    "Your data is in WIDE format (one row per firm, many time columns).\n",
    "For panel analysis, we need LONG format (one row per firm-time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify firm identifier column\n",
    "# UPDATE THESE BASED ON YOUR ACTUAL COLUMN NAMES\n",
    "FIRM_ID_COL = None\n",
    "FIRM_NAME_COL = None\n",
    "\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'ticker' in col_lower or 'symbol' in col_lower:\n",
    "        FIRM_ID_COL = col\n",
    "    if 'name' in col_lower and 'company' in col_lower:\n",
    "        FIRM_NAME_COL = col\n",
    "\n",
    "print(f\"Firm ID column: {FIRM_ID_COL}\")\n",
    "print(f\"Firm Name column: {FIRM_NAME_COL}\")\n",
    "\n",
    "# Create a simple firm ID if not found\n",
    "if FIRM_ID_COL is None:\n",
    "    df['firm_id'] = range(len(df))\n",
    "    FIRM_ID_COL = 'firm_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_time_from_column(col_name):\n",
    "    \"\"\"\n",
    "    Extract time period from column name.\n",
    "    Returns: (base_metric, time_offset, time_type)\n",
    "    \n",
    "    Examples:\n",
    "    - 'Revenue [LTM]' -> ('Revenue', 0, 'LTM')\n",
    "    - 'Revenue [LTM - 4]' -> ('Revenue', 4, 'LTM')\n",
    "    - 'Market Cap [Latest]' -> ('Market Cap', 0, 'Annual')\n",
    "    - 'Market Cap [Latest - 3 Year(s)]' -> ('Market Cap', 3, 'Annual')\n",
    "    - 'Cash [Latest Quarter]' -> ('Cash', 0, 'Quarterly')\n",
    "    - 'Cash [Latest Quarter - 8]' -> ('Cash', 8, 'Quarterly')\n",
    "    \"\"\"\n",
    "    # Pattern for LTM columns\n",
    "    ltm_pattern = r'(.+?)\\s*\\[LTM(?:\\s*-\\s*(\\d+))?\\]'\n",
    "    # Pattern for Annual columns\n",
    "    annual_pattern = r'(.+?)\\s*\\[Latest(?:\\s*-\\s*(\\d+)\\s*Year)?'\n",
    "    # Pattern for Quarterly columns\n",
    "    quarterly_pattern = r'(.+?)\\s*\\[Latest\\s*Quarter(?:\\s*-\\s*(\\d+))?\\]'\n",
    "    \n",
    "    # Try LTM first\n",
    "    match = re.search(ltm_pattern, col_name, re.IGNORECASE)\n",
    "    if match:\n",
    "        metric = match.group(1).strip()\n",
    "        offset = int(match.group(2)) if match.group(2) else 0\n",
    "        return (metric, offset, 'LTM')\n",
    "    \n",
    "    # Try Quarterly\n",
    "    match = re.search(quarterly_pattern, col_name, re.IGNORECASE)\n",
    "    if match:\n",
    "        metric = match.group(1).strip()\n",
    "        offset = int(match.group(2)) if match.group(2) else 0\n",
    "        return (metric, offset, 'Quarterly')\n",
    "    \n",
    "    # Try Annual\n",
    "    match = re.search(annual_pattern, col_name, re.IGNORECASE)\n",
    "    if match:\n",
    "        metric = match.group(1).strip()\n",
    "        offset = int(match.group(2)) if match.group(2) else 0\n",
    "        return (metric, offset, 'Annual')\n",
    "    \n",
    "    return (col_name, None, None)\n",
    "\n",
    "# Test the function\n",
    "test_cols = [\n",
    "    'Revenue [LTM]',\n",
    "    'Revenue [LTM - 4]',\n",
    "    'Market Cap [Latest]',\n",
    "    'Market Cap [Latest - 3 Year(s)]',\n",
    "    'Cash [Latest Quarter]',\n",
    "    'Cash [Latest Quarter - 8]'\n",
    "]\n",
    "\n",
    "print(\"Column parsing test:\")\n",
    "for col in test_cols:\n",
    "    result = extract_time_from_column(col)\n",
    "    print(f\"  {col:40} -> {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all columns\n",
    "column_info = []\n",
    "for col in df.columns:\n",
    "    metric, offset, time_type = extract_time_from_column(col)\n",
    "    column_info.append({\n",
    "        'original_col': col,\n",
    "        'metric': metric,\n",
    "        'time_offset': offset,\n",
    "        'time_type': time_type\n",
    "    })\n",
    "\n",
    "col_df = pd.DataFrame(column_info)\n",
    "print(f\"Total columns: {len(col_df)}\")\n",
    "print(f\"\\nTime series columns by type:\")\n",
    "print(col_df['time_type'].value_counts(dropna=False))\n",
    "\n",
    "# Show sample of parsed columns\n",
    "print(\"\\nSample parsed columns:\")\n",
    "display(col_df[col_df['time_type'].notna()].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_to_long_panel(df, firm_id_col, col_df, time_type='LTM'):\n",
    "    \"\"\"\n",
    "    Convert wide format to long panel format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame in wide format\n",
    "    firm_id_col : column name for firm identifier\n",
    "    col_df : DataFrame with column parsing info\n",
    "    time_type : 'LTM', 'Quarterly', or 'Annual'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame in long format (firm_id, time, metric1, metric2, ...)\n",
    "    \"\"\"\n",
    "    # Filter to relevant time type\n",
    "    time_cols = col_df[col_df['time_type'] == time_type].copy()\n",
    "    \n",
    "    if len(time_cols) == 0:\n",
    "        print(f\"No columns found for time_type={time_type}\")\n",
    "        return None\n",
    "    \n",
    "    # Get unique time offsets\n",
    "    time_offsets = sorted(time_cols['time_offset'].unique())\n",
    "    print(f\"Time offsets found: {time_offsets}\")\n",
    "    \n",
    "    # Get unique metrics\n",
    "    metrics = time_cols['metric'].unique()\n",
    "    print(f\"Metrics found: {len(metrics)}\")\n",
    "    \n",
    "    # Build long format\n",
    "    panels = []\n",
    "    \n",
    "    for offset in time_offsets:\n",
    "        # Get columns for this time period\n",
    "        period_cols = time_cols[time_cols['time_offset'] == offset]\n",
    "        \n",
    "        # Create mapping from original column to metric name\n",
    "        col_mapping = dict(zip(period_cols['original_col'], period_cols['metric']))\n",
    "        \n",
    "        # Select and rename columns\n",
    "        cols_to_select = [firm_id_col] + list(col_mapping.keys())\n",
    "        cols_available = [c for c in cols_to_select if c in df.columns]\n",
    "        \n",
    "        if len(cols_available) <= 1:\n",
    "            continue\n",
    "            \n",
    "        period_df = df[cols_available].copy()\n",
    "        period_df = period_df.rename(columns=col_mapping)\n",
    "        period_df['time_offset'] = offset\n",
    "        \n",
    "        panels.append(period_df)\n",
    "    \n",
    "    if not panels:\n",
    "        return None\n",
    "    \n",
    "    # Combine all time periods\n",
    "    panel = pd.concat(panels, ignore_index=True)\n",
    "    \n",
    "    # Sort by firm and time\n",
    "    panel = panel.sort_values([firm_id_col, 'time_offset'])\n",
    "    \n",
    "    return panel\n",
    "\n",
    "# Create panel for LTM metrics (quarterly frequency)\n",
    "panel_ltm = wide_to_long_panel(df, FIRM_ID_COL, col_df, time_type='LTM')\n",
    "if panel_ltm is not None:\n",
    "    print(f\"\\nLTM Panel shape: {panel_ltm.shape}\")\n",
    "    display(panel_ltm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create quarterly balance sheet panel\n",
    "panel_quarterly = wide_to_long_panel(df, FIRM_ID_COL, col_df, time_type='Quarterly')\n",
    "if panel_quarterly is not None:\n",
    "    print(f\"\\nQuarterly Panel shape: {panel_quarterly.shape}\")\n",
    "    display(panel_quarterly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge panels if both exist\n",
    "if panel_ltm is not None and panel_quarterly is not None:\n",
    "    # Merge on firm_id and time_offset\n",
    "    panel = pd.merge(panel_ltm, panel_quarterly, \n",
    "                     on=[FIRM_ID_COL, 'time_offset'], \n",
    "                     how='outer',\n",
    "                     suffixes=('_ltm', '_qtr'))\n",
    "    print(f\"Merged panel shape: {panel.shape}\")\n",
    "elif panel_ltm is not None:\n",
    "    panel = panel_ltm\n",
    "else:\n",
    "    panel = panel_quarterly\n",
    "\n",
    "print(f\"Final panel: {panel.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add Treatment Variables and Time Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge AI exposure to panel\n",
    "# Get static firm characteristics from original df\n",
    "static_cols = [FIRM_ID_COL]\n",
    "\n",
    "# Add AI exposure columns if they exist\n",
    "for col in ['ai_exposure', 'ai_exposure_binary', 'ai_exposure_continuous']:\n",
    "    if col in df.columns:\n",
    "        static_cols.append(col)\n",
    "\n",
    "# Add identifier columns\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if any(kw in col_lower for kw in ['industry', 'sector', 'country', 'exchange', 'type']):\n",
    "        if col not in static_cols:\n",
    "            static_cols.append(col)\n",
    "\n",
    "print(f\"Static columns to merge: {static_cols}\")\n",
    "\n",
    "# Merge\n",
    "static_df = df[static_cols].drop_duplicates(subset=[FIRM_ID_COL])\n",
    "panel = pd.merge(panel, static_df, on=FIRM_ID_COL, how='left')\n",
    "print(f\"Panel shape after merge: {panel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time_offset to actual calendar time\n",
    "# IMPORTANT: Update BASE_DATE based on when \"Latest\" refers to in your data\n",
    "\n",
    "# Assuming \"Latest\" = most recent available (e.g., Q4 2024 or Q3 2024)\n",
    "# UPDATE THIS based on your data\n",
    "BASE_YEAR = 2024\n",
    "BASE_QUARTER = 4  # Q4\n",
    "\n",
    "def offset_to_quarter(offset, base_year, base_quarter):\n",
    "    \"\"\"\n",
    "    Convert quarter offset to (year, quarter).\n",
    "    offset=0 is the base period, offset=4 is 1 year ago, etc.\n",
    "    \"\"\"\n",
    "    total_quarters = base_year * 4 + base_quarter - offset\n",
    "    year = (total_quarters - 1) // 4\n",
    "    quarter = ((total_quarters - 1) % 4) + 1\n",
    "    return year, quarter\n",
    "\n",
    "# Apply to panel\n",
    "panel['year'], panel['quarter'] = zip(*panel['time_offset'].apply(\n",
    "    lambda x: offset_to_quarter(x, BASE_YEAR, BASE_QUARTER)\n",
    "))\n",
    "\n",
    "# Create period identifier (e.g., 2022Q4)\n",
    "panel['period'] = panel['year'].astype(str) + 'Q' + panel['quarter'].astype(str)\n",
    "\n",
    "# Create datetime for plotting\n",
    "panel['date'] = pd.to_datetime(panel['year'].astype(str) + '-' + \n",
    "                                ((panel['quarter']-1)*3 + 1).astype(str) + '-01')\n",
    "\n",
    "print(\"Time periods in panel:\")\n",
    "print(panel[['time_offset', 'year', 'quarter', 'period']].drop_duplicates().sort_values('time_offset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create POST indicator (after ChatGPT release Nov 2022)\n",
    "# ChatGPT released Nov 30, 2022 -> first full quarter is Q1 2023\n",
    "CHATGPT_RELEASE_YEAR = 2022\n",
    "CHATGPT_RELEASE_QUARTER = 4  # Q4 2022 is the shock quarter\n",
    "\n",
    "panel['post_chatgpt'] = ((panel['year'] > CHATGPT_RELEASE_YEAR) | \n",
    "                          ((panel['year'] == CHATGPT_RELEASE_YEAR) & \n",
    "                           (panel['quarter'] > CHATGPT_RELEASE_QUARTER))).astype(int)\n",
    "\n",
    "# Alternative: include Q4 2022 as post\n",
    "panel['post_chatgpt_inclusive'] = ((panel['year'] > CHATGPT_RELEASE_YEAR) | \n",
    "                                    ((panel['year'] == CHATGPT_RELEASE_YEAR) & \n",
    "                                     (panel['quarter'] >= CHATGPT_RELEASE_QUARTER))).astype(int)\n",
    "\n",
    "print(f\"\\nPost-ChatGPT observations (exclusive): {panel['post_chatgpt'].sum()} / {len(panel)}\")\n",
    "print(f\"Post-ChatGPT observations (inclusive): {panel['post_chatgpt_inclusive'].sum()} / {len(panel)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create event time variable for event study\n",
    "# Event time = quarters relative to Q4 2022\n",
    "event_quarter = CHATGPT_RELEASE_YEAR * 4 + CHATGPT_RELEASE_QUARTER\n",
    "panel['event_time'] = (panel['year'] * 4 + panel['quarter']) - event_quarter\n",
    "\n",
    "print(\"Event time distribution:\")\n",
    "print(panel['event_time'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DiD interaction term\n",
    "treatment_col = 'ai_exposure_binary' if 'ai_exposure_binary' in panel.columns else 'ai_exposure'\n",
    "\n",
    "if treatment_col in panel.columns:\n",
    "    panel['treated_x_post'] = panel[treatment_col] * panel['post_chatgpt']\n",
    "    print(f\"DiD interaction (Treated × Post):\")\n",
    "    print(panel['treated_x_post'].value_counts())\n",
    "else:\n",
    "    print(f\"Treatment column not found. Run notebook 02 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outcome variables\n",
    "outcome_candidates = ['Revenue', 'EBITDA', 'Net Income', 'Operating Income',\n",
    "                      'R&D', 'CapEx', 'Employee', 'Cash', 'Total Debt']\n",
    "\n",
    "outcome_cols = []\n",
    "for col in panel.columns:\n",
    "    for candidate in outcome_candidates:\n",
    "        if candidate.lower() in col.lower():\n",
    "            outcome_cols.append(col)\n",
    "            break\n",
    "\n",
    "outcome_cols = list(set(outcome_cols))\n",
    "print(f\"Outcome variables found: {outcome_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by treatment group\n",
    "if treatment_col in panel.columns and len(outcome_cols) > 0:\n",
    "    # Pre-period statistics\n",
    "    pre_period = panel[panel['post_chatgpt'] == 0]\n",
    "    \n",
    "    print(\"Summary Statistics: Pre-ChatGPT Period\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    summary_data = []\n",
    "    for col in outcome_cols[:10]:  # First 10 outcomes\n",
    "        if col in pre_period.columns:\n",
    "            treated = pre_period[pre_period[treatment_col] == 1][col]\n",
    "            control = pre_period[pre_period[treatment_col] == 0][col]\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Variable': col[:40],\n",
    "                'Treated Mean': treated.mean(),\n",
    "                'Treated SD': treated.std(),\n",
    "                'Control Mean': control.mean(),\n",
    "                'Control SD': control.std(),\n",
    "                'Diff': treated.mean() - control.mean()\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parallel Trends Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parallel_trends(panel, outcome_col, treatment_col, date_col='date', \n",
    "                         event_date='2022-11-01', title=None):\n",
    "    \"\"\"\n",
    "    Plot parallel trends for treatment and control groups.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Group by time and treatment\n",
    "    trends = panel.groupby([date_col, treatment_col])[outcome_col].mean().reset_index()\n",
    "    \n",
    "    # Plot each group\n",
    "    for treat_val in [0, 1]:\n",
    "        group_data = trends[trends[treatment_col] == treat_val]\n",
    "        label = 'High AI Exposure' if treat_val == 1 else 'Low AI Exposure'\n",
    "        color = 'steelblue' if treat_val == 1 else 'coral'\n",
    "        ax.plot(group_data[date_col], group_data[outcome_col], \n",
    "                marker='o', label=label, color=color, linewidth=2)\n",
    "    \n",
    "    # Add vertical line for event\n",
    "    ax.axvline(pd.to_datetime(event_date), color='red', linestyle='--', \n",
    "               label='ChatGPT Release', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(outcome_col)\n",
    "    ax.set_title(title or f'Parallel Trends: {outcome_col}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Plot for key outcomes\n",
    "if treatment_col in panel.columns and len(outcome_cols) > 0:\n",
    "    for outcome in outcome_cols[:4]:\n",
    "        if outcome in panel.columns and panel[outcome].notna().sum() > 100:\n",
    "            fig = plot_parallel_trends(panel, outcome, treatment_col)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Difference-in-Differences Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_did_regression(panel, outcome, treatment_col, firm_id, \n",
    "                       time_var='period', cluster_var=None):\n",
    "    \"\"\"\n",
    "    Run DiD regression with firm and time fixed effects.\n",
    "    \n",
    "    Y_it = α_i + α_t + β(Treated_i × Post_t) + ε_it\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    reg_data = panel[[firm_id, time_var, outcome, treatment_col, \n",
    "                      'post_chatgpt', 'treated_x_post']].dropna()\n",
    "    \n",
    "    if len(reg_data) < 100:\n",
    "        print(f\"Insufficient observations for {outcome}: {len(reg_data)}\")\n",
    "        return None\n",
    "    \n",
    "    # Set index for panel\n",
    "    reg_data = reg_data.set_index([firm_id, time_var])\n",
    "    \n",
    "    # Define variables\n",
    "    y = reg_data[outcome]\n",
    "    X = reg_data[['treated_x_post']]\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Run regression with fixed effects\n",
    "    try:\n",
    "        model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "        results = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error running regression for {outcome}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"DiD regression function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DiD for each outcome\n",
    "did_results = {}\n",
    "\n",
    "if 'treated_x_post' in panel.columns:\n",
    "    for outcome in outcome_cols[:8]:  # First 8 outcomes\n",
    "        if outcome in panel.columns:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Outcome: {outcome}\")\n",
    "            print('='*60)\n",
    "            \n",
    "            result = run_did_regression(panel, outcome, treatment_col, FIRM_ID_COL)\n",
    "            if result:\n",
    "                did_results[outcome] = result\n",
    "                print(result.summary.tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use pyfixest for faster/simpler syntax\n",
    "if 'treated_x_post' in panel.columns and len(outcome_cols) > 0:\n",
    "    outcome = outcome_cols[0]\n",
    "    \n",
    "    # Prepare for pyfixest\n",
    "    reg_df = panel[[FIRM_ID_COL, 'period', outcome, 'treated_x_post']].dropna().copy()\n",
    "    reg_df['firm_fe'] = reg_df[FIRM_ID_COL].astype('category')\n",
    "    reg_df['time_fe'] = reg_df['period'].astype('category')\n",
    "    \n",
    "    try:\n",
    "        # Two-way fixed effects regression\n",
    "        fit = pf.feols(f\"{outcome} ~ treated_x_post | firm_fe + time_fe\", \n",
    "                       data=reg_df, vcov={'CRV1': 'firm_fe'})\n",
    "        print(f\"\\nPyFixest Results for {outcome}:\")\n",
    "        print(fit.summary())\n",
    "    except Exception as e:\n",
    "        print(f\"Pyfixest error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Event Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_event_study(panel, outcome, treatment_col, firm_id, event_time_col='event_time',\n",
    "                    omit_period=-1, min_period=-12, max_period=8):\n",
    "    \"\"\"\n",
    "    Run event study regression.\n",
    "    \n",
    "    Y_it = α_i + α_t + Σ_k β_k (Treated_i × 1{t=k}) + ε_it\n",
    "    \n",
    "    Omit period -1 (one quarter before) as reference.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    reg_data = panel[[firm_id, 'period', event_time_col, outcome, treatment_col]].dropna()\n",
    "    \n",
    "    # Filter to event window\n",
    "    reg_data = reg_data[(reg_data[event_time_col] >= min_period) & \n",
    "                        (reg_data[event_time_col] <= max_period)]\n",
    "    \n",
    "    if len(reg_data) < 100:\n",
    "        print(f\"Insufficient observations for {outcome}\")\n",
    "        return None\n",
    "    \n",
    "    # Create event time dummies interacted with treatment\n",
    "    event_times = sorted(reg_data[event_time_col].unique())\n",
    "    \n",
    "    for t in event_times:\n",
    "        if t != omit_period:\n",
    "            col_name = f'treat_x_t{t}'\n",
    "            reg_data[col_name] = (reg_data[event_time_col] == t).astype(int) * reg_data[treatment_col]\n",
    "    \n",
    "    # Get interaction columns\n",
    "    interact_cols = [c for c in reg_data.columns if c.startswith('treat_x_t')]\n",
    "    \n",
    "    # Set index\n",
    "    reg_data_indexed = reg_data.set_index([firm_id, 'period'])\n",
    "    \n",
    "    # Run regression\n",
    "    y = reg_data_indexed[outcome]\n",
    "    X = reg_data_indexed[interact_cols]\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    try:\n",
    "        model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "        results = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "        \n",
    "        # Extract coefficients for plotting\n",
    "        coefs = []\n",
    "        for t in event_times:\n",
    "            if t == omit_period:\n",
    "                coefs.append({'event_time': t, 'coef': 0, 'se': 0, 'ci_low': 0, 'ci_high': 0})\n",
    "            else:\n",
    "                col_name = f'treat_x_t{t}'\n",
    "                if col_name in results.params.index:\n",
    "                    coef = results.params[col_name]\n",
    "                    se = results.std_errors[col_name]\n",
    "                    coefs.append({\n",
    "                        'event_time': t,\n",
    "                        'coef': coef,\n",
    "                        'se': se,\n",
    "                        'ci_low': coef - 1.96 * se,\n",
    "                        'ci_high': coef + 1.96 * se\n",
    "                    })\n",
    "        \n",
    "        coef_df = pd.DataFrame(coefs)\n",
    "        return results, coef_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in event study: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Event study function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_study(coef_df, outcome_name, save_path=None):\n",
    "    \"\"\"\n",
    "    Create publication-quality event study plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot confidence intervals\n",
    "    ax.fill_between(coef_df['event_time'], coef_df['ci_low'], coef_df['ci_high'],\n",
    "                    alpha=0.2, color='steelblue')\n",
    "    \n",
    "    # Plot point estimates\n",
    "    ax.plot(coef_df['event_time'], coef_df['coef'], 'o-', \n",
    "            color='steelblue', linewidth=2, markersize=8)\n",
    "    \n",
    "    # Reference lines\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=1, \n",
    "               label='ChatGPT Release (Q4 2022)')\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel('Quarters Relative to ChatGPT Release', fontsize=12)\n",
    "    ax.set_ylabel(f'Effect on {outcome_name}', fontsize=12)\n",
    "    ax.set_title(f'Event Study: Effect of AI Exposure on {outcome_name}', fontsize=14)\n",
    "    \n",
    "    # Grid and legend\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"Event study plotting function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run event study for key outcomes\n",
    "event_study_results = {}\n",
    "\n",
    "if treatment_col in panel.columns:\n",
    "    for outcome in outcome_cols[:4]:  # First 4 outcomes\n",
    "        if outcome in panel.columns and panel[outcome].notna().sum() > 100:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Event Study: {outcome}\")\n",
    "            print('='*60)\n",
    "            \n",
    "            result = run_event_study(panel, outcome, treatment_col, FIRM_ID_COL)\n",
    "            \n",
    "            if result:\n",
    "                model_result, coef_df = result\n",
    "                event_study_results[outcome] = {'model': model_result, 'coefs': coef_df}\n",
    "                \n",
    "                # Plot\n",
    "                fig = plot_event_study(coef_df, outcome)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness 1: Different clustering (industry level)\n",
    "print(\"Robustness checks to implement:\")\n",
    "print(\"1. Industry-level clustering\")\n",
    "print(\"2. Continuous treatment measure\")\n",
    "print(\"3. Alternative event windows\")\n",
    "print(\"4. Placebo test with fake event dates\")\n",
    "print(\"5. Exclude specific industries\")\n",
    "print(\"6. Control for COVID effects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robustness 2: Continuous treatment\n",
    "if 'ai_exposure_continuous' in panel.columns:\n",
    "    panel['continuous_treat_x_post'] = panel['ai_exposure_continuous'] * panel['post_chatgpt']\n",
    "    \n",
    "    print(\"\\nContinuous Treatment DiD:\")\n",
    "    for outcome in outcome_cols[:3]:\n",
    "        if outcome in panel.columns:\n",
    "            reg_data = panel[[FIRM_ID_COL, 'period', outcome, 'continuous_treat_x_post']].dropna()\n",
    "            if len(reg_data) > 100:\n",
    "                reg_data = reg_data.set_index([FIRM_ID_COL, 'period'])\n",
    "                y = reg_data[outcome]\n",
    "                X = sm.add_constant(reg_data[['continuous_treat_x_post']])\n",
    "                \n",
    "                model = PanelOLS(y, X, entity_effects=True, time_effects=True)\n",
    "                result = model.fit(cov_type='clustered', cluster_entity=True)\n",
    "                \n",
    "                print(f\"\\n{outcome}:\")\n",
    "                coef = result.params['continuous_treat_x_post']\n",
    "                se = result.std_errors['continuous_treat_x_post']\n",
    "                print(f\"  Coefficient: {coef:.4f} (SE: {se:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save panel data\n",
    "panel.to_parquet(DATA_PATH / 'panel_data_analysis.parquet', index=False)\n",
    "print(f\"Panel data saved to: {DATA_PATH / 'panel_data_analysis.parquet'}\")\n",
    "\n",
    "# Save event study coefficients\n",
    "if event_study_results:\n",
    "    all_coefs = []\n",
    "    for outcome, results in event_study_results.items():\n",
    "        coef_df = results['coefs'].copy()\n",
    "        coef_df['outcome'] = outcome\n",
    "        all_coefs.append(coef_df)\n",
    "    \n",
    "    if all_coefs:\n",
    "        all_coefs_df = pd.concat(all_coefs, ignore_index=True)\n",
    "        all_coefs_df.to_csv(DATA_PATH / 'event_study_coefficients.csv', index=False)\n",
    "        print(f\"Event study coefficients saved to: {DATA_PATH / 'event_study_coefficients.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "1. [To be filled after running]\n",
    "2. [To be filled after running]\n",
    "\n",
    "### Next Steps:\n",
    "1. Run robustness checks in detail\n",
    "2. Add heterogeneity analysis (by firm size, financial constraints)\n",
    "3. Create publication-ready tables and figures\n",
    "4. Write up results section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal firms: {panel[FIRM_ID_COL].nunique():,}\")\n",
    "print(f\"Total observations: {len(panel):,}\")\n",
    "print(f\"Time periods: {panel['period'].nunique()}\")\n",
    "print(f\"\\nDiD regressions run: {len(did_results)}\")\n",
    "print(f\"Event studies run: {len(event_study_results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
